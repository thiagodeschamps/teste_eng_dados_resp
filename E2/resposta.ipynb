{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding pyspark to sys.path at runtime\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/09 09:44:26 WARN Utils: Your hostname, BRSPOBITANL1859 resolves to a loopback address: 127.0.1.1; using 192.168.0.60 instead (on interface wlp0s20f3)\n",
      "22/12/09 09:44:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/09 09:44:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "                    .appName('resp-entregavel_2')\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abaixo temos as informações fornecidas através da imagem sobre o conjunto de dados que iremos trabalhar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](src/data.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcrevendo os dados\n",
    "transacoes = [{'transacao_id':1, 'total_bruto':3000, 'desconto_percentual':6.99},\n",
    "              {'transacao_id':2, 'total_bruto':57989, 'desconto_percentual':1.45},\n",
    "              {'transacao_id':4, 'total_bruto':1, 'desconto_percentual':None},\n",
    "              {'transacao_id':5, 'total_bruto':34, 'desconto_percentual':0.0}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já temos os dados em formato de 'lista de dicionários', vamos criar um dataframe usando a função do Spark createDataframe e já aproveitando preenchendo o valor nulo com 0, através da função na.fill, e logo em seguida vamos mostrar os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+\n",
      "|desconto_percentual|total_bruto|transacao_id|\n",
      "+-------------------+-----------+------------+\n",
      "|               6.99|       3000|           1|\n",
      "|               1.45|      57989|           2|\n",
      "|                0.0|          1|           4|\n",
      "|                0.0|         34|           5|\n",
      "+-------------------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(transacoes).na.fill(0)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender melhor sobre a estrutura do dataframe podemos usar a função printSchema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- desconto_percentual: double (nullable = false)\n",
      " |-- total_bruto: long (nullable = true)\n",
      " |-- transacao_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos calcular o total líquido da empresa. Esse total é calculado da seguinte forma total_liquido = soma(total_bruto – desconto_percentual).\n",
    "\n",
    "O resultado esperado é um total liquido de 59973.46."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, vamos seguir a mesma idea da atividade anterior, vamos calcular o desconto (100-desconto_percentual)% e multiplicar o resultado pelo total bruto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+------------+-------------+\n",
      "|desconto_percentual|total_bruto|transacao_id|total_liquido|\n",
      "+-------------------+-----------+------------+-------------+\n",
      "|               6.99|       3000|           1|       2790.3|\n",
      "|               1.45|      57989|           2|   57148.1595|\n",
      "|                0.0|          1|           4|          1.0|\n",
      "|                0.0|         34|           5|         34.0|\n",
      "+-------------------+-----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('total_liquido', ( df['total_bruto'] * (100 - df['desconto_percentual'])/100))\n",
    "\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora para calcular a soma do total_liquido, precisamos importar a função sum de pyspark.sql.functions e fazer o cálculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|sum(total_liquido)|\n",
      "+------------------+\n",
      "|59973.459500000004|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "df.select(f.sum('total_liquido')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E assim obtemos a resposta, que é 59973.459500000004 :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
